# Vision Service (vendored)

This folder contains a vendored copy of the ``naturalia`` inference code and a small FastAPI wrapper used to run the iNaturalist / MetaFormer classifier locally for development and testing.

Summary
- The inference code here is derived from the Hugging Face Space: https://huggingface.co/spaces/chsezech/naturalia and uses the model weights from the HF model repo `joshvm/inaturalist_sgd_4k`.
- The vendored source is licensed under MIT (see `naturalia/LICENSE` in this folder).

Status (verified)
- The service has been validated to run independently from the top-level clone: model code and downloaded artifacts live under `backend/vision_service/naturalia`.
- You can safely back up or remove the root-level `iNatAPI` folder once you confirm the vendored folder contains the downloaded weights and you no longer need the original copy.

What lives in this folder
- `naturalia/` — vendored Space source code (inference code, model config and metadata). Large model weight files are intentionally not committed; they are downloaded on first run into this folder.
- `run_local_infer.py` — CLI helper to run inference on a local image and to download model artifacts into the vendored folder if missing.
- `app.py` — FastAPI wrapper exposing `/predict` and storing downloaded model files under the vendored `naturalia` directory.
- `download_model.py` — helper to download required support files directly into the vendored folder.
- `vendor_naturalia.ps1` — PowerShell helper (keeps behavior tolerant if the top-level `iNatAPI` is absent).

Important notes
- Model weights (e.g. `*.pth`, `*.safetensors`) are large and are excluded from the vendored copy to avoid bloating the repository. The first time you run `run_local_infer.py` or start the FastAPI service, the code will download needed model artifacts via the Hugging Face Hub and place them under `backend/vision_service/naturalia`.
- The vendored service has been tested locally and writes artifacts into the vendored folder; see the "Status (verified)" section above.
- Keep `HUGGINGFACE_TOKEN` secret and set it in your environment if the HF model requires authentication.

Minimal install & quick start (PowerShell, recommended)
```powershell
cd backend\vision_service
# Create and activate a venv
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# Install minimal service deps
python -m pip install --upgrade pip
python -m pip install -r requirements_cpu.txt

# Install additional helpers
python -m pip install transformers timm huggingface-hub safetensors

# Install PyTorch (CPU wheel example)
python -m pip install torch --index-url https://download.pytorch.org/whl/cpu

# Optional: explicitly download the support files into the vendored folder
python download_model.py

# Run one-off inference (will download weights into vendored dir if missing)
python run_local_infer.py --image "C:\Users\LENOVO\Downloads\butterfly.jpg" --topk 5

# Or run the FastAPI server
uvicorn backend.vision_service.app:app --reload --port 8080

# Quick test (PowerShell)
$body = @{ imageUrl = 'https://upload.wikimedia.org/...' ; top_k = 5 } | ConvertTo-Json
Invoke-RestMethod -Method Post -Uri http://localhost:8080/predict -Headers @{ 'Content-Type' = 'application/json' } -Body $body | ConvertTo-Json -Depth 5
```

Docker (optional)
- The Dockerfile in this folder copies the vendored `naturalia` directory and builds a container. See the top of this folder for the Dockerfile.

Security and trust
- The code may fall back to performing a full `torch.load` for some checkpoint formats. Only use model weights from trusted sources and keep any HF tokens private.

Removing the top-level `iNatAPI` folder
- The vendored service now runs independently. If you no longer need the root-level `iNatAPI` clone, back it up first (e.g. rename to `iNatAPI.backup`) and confirm the vendored folder contains the downloaded weights before deleting.

If you want me to:
- Commit the vendored `naturalia` source here (excluding weights), or
- Add a `.gitignore` entry to block model weights (`*.pth`, `*.safetensors`), or
- Move the top-level `iNatAPI` to `iNatAPI.backup` for you and run a final grep to confirm no runtime references remain.

---
Generated by the project maintainers to document the vendored vision service and attribution.
