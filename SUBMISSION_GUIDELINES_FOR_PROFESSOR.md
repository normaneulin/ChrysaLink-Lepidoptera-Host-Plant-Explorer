**ChrysaLink — Submission Guidelines for Professor**

This document explains exactly what to prepare and submit for the ChrysaLink project deliverable. It covers items A–D from the assignment and includes concrete commands, file lists, and examples so you can assemble the submission zip files easily.

**Important:** Do NOT include any secret keys or tokens (Hugging Face tokens, Supabase service_role keys, GitHub tokens, etc.) in the files you submit. Replace any secrets with placeholders like `REDACTED_HF_TOKEN`.

---

**A. Zipped copy of the database with pre-migrated datasets**

- Purpose: provide a copy of the database contents (data rows) that testers can import locally or into a test Supabase/Postgres instance so they can reproduce test cases.

- What to include:
  - A full SQL dump (recommended) of the schema and data, OR CSV exports of each relevant table.
  - A short README (named `db_import_README.txt`) with import instructions, required Postgres version, and sample pg_dump/psql commands.

- Recommended files and naming inside the zip `chrysalink_database_PREMIGRATED.zip`:
  - `schema_and_data.sql` — generated by `pg_dump` or `pg_dumpall` containing schema + data.
  - `tables/` — optional folder with individual CSVs like `users.csv`, `observations.csv`, `plants.csv`, `lepidoptera.csv`, `relationship_db.csv` (useful if professor prefers CSV import).
  - `db_import_README.txt` — short import steps.

- How to create a SQL dump (Supabase / Postgres remote database):

  1. Obtain the connection info from Supabase (Host, Port, DB name, User). Use the service_role or an account with read access to tables.

  2. From a machine with `pg_dump` installed (or from Cloud Shell), run:

  ```powershell
  # PowerShell example (replace placeholders)
  $PGHOST = 'db.xyz.supabase.co'
  $PGPORT = 5432
  $PGUSER = 'postgres'
  $PGPASSWORD = 'REDACTED_PASSWORD'
  $PGDATABASE = 'postgres'

  # Export schema + data
  pg_dump --host=$PGHOST --port=$PGPORT --username=$PGUSER --format=plain --no-owner --no-privileges --dbname=$PGDATABASE --file=schema_and_data.sql
  ```

  If you cannot run `pg_dump`, export per-table CSVs from Supabase UI or use `COPY`:

  ```sql
  COPY public.users TO STDOUT WITH CSV HEADER;
  ```

- db_import_README.txt example contents (include in zip):

  - Instructions to create a local Postgres DB and import the `schema_and_data.sql` file.
  - Example:

  ```text
  1. Create local DB: createdb chrysalink_test
  2. Import: psql -d chrysalink_test -f schema_and_data.sql
  3. Or import CSVs using psql \copy:
     \copy users FROM 'tables/users.csv' CSV HEADER;
  ```

---

**B. Zipped copy of the final software project (source + deployment)**

- Purpose: provide the professor the complete project source and the running/deployed artifact (URL or executable).

- What to include in `ChrysaLink_project_FINAL.zip`:
  - `frontend/` — source for the client (include `package.json`, `src/`, `public/`, and instructions to run).
  - `backend/` — entire backend folder (including `vision_service/`, `tools/`, `supabase/` migrations, etc.).
  - `README_SUBMISSION.md` — special-run README describing how to run the app locally and how to use the deployed URL.
  - `deploy_info.txt` — includes the public URL(s) for the deployed frontend and backend (e.g., Vercel URL and Render URL) and any caveats about cold starts.
  - Optional: compiled artifact if required (Windows `.exe`, Linux binary, or Docker image tar). If your project is web-based and hosted, provide the public URLs instead of an `.exe`.

- Example contents of `README_SUBMISSION.md`:

  - How to run frontend locally:
    ```powershell
    cd frontend
    npm install
    npm run dev
    ```

  - How to run backend locally (vision service):
    ```powershell
    cd backend/vision_service
    python -m venv .venv
    .\.venv\Scripts\Activate.ps1
    pip install -r requirements.txt
    python download_model.py  # only if you want the model locally
    uvicorn app:app --host 0.0.0.0 --port 8000
    ```

  - Deployed URLs (example):
    - Frontend: `https://chrysalink-frontend.vercel.app`
    - Backend (vision): `https://chrysalink-vision-service.onrender.com`

---

**C. List of login credentials of sample users**

- Purpose: let the professor use accounts that exercise all test cases (admin, curator, regular user).

- Provide a file named `SAMPLE_USERS_CREDENTIALS.csv` (and `SAMPLE_USERS_CREDENTIALS.txt` for convenience) containing:
  - `username,email,password,role,notes`

- Example rows (ensure these accounts exist in the pre-migrated DB):

  ```csv
  username,email,password,role,notes
  admin,admin@example.com,Passw0rd!,admin,Has full permissions; can create users and approve IDs
  curator,curator@example.com,Curate123!,curator,Can edit species and relationships
  alice,alice@example.com,User123!,user,Regular user with sample observations
  bob,bob@example.com,User123!,user,Regular user with sample plant uploads
  ```

- Also provide SQL statements in a file `create_sample_users.sql` which the professor can run to insert these users (use hashed passwords or plain text depending on how your auth works). Example (Postgres):

  ```sql
  INSERT INTO users (username, email, password, role) VALUES
  ('admin','admin@example.com','$2b$12$...hashed...', 'admin'),
  ('curator','curator@example.com','$2b$12$...hashed...', 'curator');
  ```

  If your project uses Supabase Auth, include instructions to create these users via the Supabase UI or using the Admin API (do NOT include your service_role key in the submission). Instead provide `create_sample_users_instructions.txt` explaining how to add them.

---

**D. Worksheet listing pre-migrated test datasets**

- Purpose: give the professor a single reference that documents the datasets included, so they know which tables to inspect and which test cases map to which data rows.

- Provide a spreadsheet-style markdown file `TEST_DATASETS_WORKSHEET.md` (or `TEST_DATASETS_WORKSHEET.xlsx`) with the following columns:
  - `Dataset name` — e.g. `lepidoptera`, `plant`, `observations`, `relationship_db`
  - `Source file` — path inside the zip (e.g. `tables/lepidoptera.csv` or `schema_and_data.sql`)
  - `Row count` — number of rows included
  - `Key fields` — primary keys or important columns (e.g. `taxon_id`, `scientific_name`, `common_name`)
  - `Related test cases` — which manual tests rely on this data (e.g. `Test 4: Search by scientific name`)
  - `Notes` — any special notes (e.g. sample images referenced in `public/`)

- Example `TEST_DATASETS_WORKSHEET.md` snippet:

  | Dataset name | Source file | Row count | Key fields | Related test cases | Notes |
  |--------------|-------------|-----------:|------------|--------------------|-------|
  | lepidoptera  | tables/lepidoptera.csv | 420 | taxon_id,scientific_name | Search, Species page | Contains taxonomic ranks
  | plant        | tables/plant.csv       | 150 | plant_id,common_name | Plant search | Includes image URLs in `public/` |

---

Additional submission tips and checklist

- Security:
  - Remove or redact any API keys or tokens.
  - If you must include a token for an enclosed test account, set it to expire and document its scope.

- Packaging checklist (what to attach in final ZIP archive(s)):
  1. `chrysalink_database_PREMIGRATED.zip` — contains `schema_and_data.sql`, `tables/`, `db_import_README.txt`.
  2. `ChrysaLink_project_FINAL.zip` — contains `frontend/`, `backend/`, `README_SUBMISSION.md`, `deploy_info.txt`.
  3. `SAMPLE_USERS_CREDENTIALS.csv` and `create_sample_users.sql` (or Supabase instructions).
  4. `TEST_DATASETS_WORKSHEET.md` (or `.xlsx`).
  5. `run_tests_quickstart.md` — short guide that lists the minimal steps to validate the main test cases (login, search species, upload observation, run vision predict).

- Quick PowerShell zip commands examples:

  ```powershell
  # Zip the pre-migrated DB folder
  Compress-Archive -Path .\db_export\* -DestinationPath ..\chrysalink_database_PREMIGRATED.zip -Force

  # Zip the project
  Compress-Archive -Path .\frontend, .\backend, .\README_SUBMISSION.md -DestinationPath ..\ChrysaLink_project_FINAL.zip -Force
  ```

- Deliverable naming convention (use these exact names):
  - `chrysalink_database_PREMIGRATED.zip`
  - `ChrysaLink_project_FINAL.zip`
  - `SAMPLE_USERS_CREDENTIALS.csv`
  - `TEST_DATASETS_WORKSHEET.md`

---

If you want, I can:
- generate the `SAMPLE_USERS_CREDENTIALS.csv` file from your local DB (I will not export real tokens), or
- prepare `TEST_DATASETS_WORKSHEET.md` automatically by scanning your `backend/data` and the `supabase/migrations` folder and reporting row counts and file paths.

Tell me which of the two extras you'd like me to do and I will create the files automatically and add them to the repo.

---

Author: ChrysaLink automation
Date: 2025-12-07
